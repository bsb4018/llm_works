{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQVIcL2LWULJ"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain==0.0.208 openai python-dotenv newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"D:/work4/activeloop_LLM/.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6rH09GpWyP_",
        "outputId": "566117d6-04d6-494d-e234-b14c582e3d1d"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from newspaper import Article\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
        "}\n",
        "\n",
        "article_urls = \"https://www.artificialintelligence-news.com/2022/01/25/meta-claims-new-ai-supercomputer-will-set-records/\"\n",
        "\n",
        "session = requests.Session()\n",
        "\n",
        "try:\n",
        "    response = session.get(article_urls, headers=headers, timeout=10)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        article = Article(article_urls)\n",
        "        article.download()\n",
        "        article.parse()\n",
        "\n",
        "        print(f\"Title: {article.title}\")\n",
        "        print(f\"Text: {article.text}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to fetch article at {article_urls}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error occurred while fetching article at {article_urls}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-neGI_O-WyH5"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import (\n",
        "    HumanMessage\n",
        ")\n",
        "\n",
        "# we get the article data from the scraping part\n",
        "article_title = article.title\n",
        "article_text = article.text\n",
        "\n",
        "# prepare template for prompt\n",
        "template = \"\"\"You are a very good assistant that summarizes online articles.\n",
        "\n",
        "Here's the article you want to summarize.\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "Write a summary of the previous article.\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(article_title=article.title, article_text=article.text)\n",
        "\n",
        "messages = [HumanMessage(content=prompt)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYRzjToAXDUe"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# load the model\n",
        "chat = ChatOpenAI(model_name=\"gpt-4\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVMxNufYXMek",
        "outputId": "05d74e4c-d8cf-47e4-d2a2-1510c8fd1687"
      },
      "outputs": [],
      "source": [
        "# generate summary\n",
        "summary = chat(messages)\n",
        "print(summary.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3LoDUVTXNJz",
        "outputId": "30c511d5-b63e-49f3-b527-11e278675338"
      },
      "outputs": [],
      "source": [
        "# prepare template for prompt\n",
        "template = \"\"\"You are an advanced AI assistant that summarizes online articles into bulleted lists.\n",
        "\n",
        "Here's the article you need to summarize.\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "Now, provide a summarized version of the article in a bulleted list format.\n",
        "\"\"\"\n",
        "\n",
        "# format prompt\n",
        "prompt = template.format(article_title=article.title, article_text=article.text)\n",
        "\n",
        "# generate summary\n",
        "summary = chat([HumanMessage(content=prompt)])\n",
        "print(summary.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPwrM1PWXtBr",
        "outputId": "b6910bb9-2413-4b1f-f292-76eb52bd7142"
      },
      "outputs": [],
      "source": [
        "# prepare template for prompt\n",
        "template = \"\"\"You are an advanced AI assistant that summarizes online articles into bulleted lists in French.\n",
        "\n",
        "Here's the article you need to summarize.\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "Now, provide a summarized version of the article in a bulleted list format, in French.\n",
        "\"\"\"\n",
        "\n",
        "# format prompt\n",
        "prompt = template.format(article_title=article.title, article_text=article.text)\n",
        "\n",
        "# generate summary\n",
        "summary = chat([HumanMessage(content=prompt)])\n",
        "print(summary.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrx20THKYkA4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
